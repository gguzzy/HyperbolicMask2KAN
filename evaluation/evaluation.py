# -*- coding: utf-8 -*-
"""evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16zi92u2zq8Ci-kMG5DYi5YUQuZnBw1Yy

## REGULAR TRAINING RESULTS (SUPERVISED AND UNSUPERVISED WEIGHTS)
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the CSV file
file_path = '/content/results_train_baseline_weights.csv'
df = pd.read_csv(file_path)

# Display the first few rows of the dataframe
df.head()

# Data Cleaning and Preparation
# Remove '%' and convert to float
df['auroc'] = df['auroc'].str.rstrip('%').astype(float)
df['auprc'] = df['auprc'].str.rstrip('%').astype(float)
df['fpr@tpr95'] = df['fpr@tpr95'].str.rstrip('%').astype(float)
df['time execution'] = df['time execution'].astype(float)

# Summary Statistics
summary_stats = df.groupby('model').agg({
    'auroc': ['mean', 'std', 'max'],
    'auprc': ['mean', 'std', 'max'],
    'fpr@tpr95': ['mean', 'std', 'min'],
    'time execution': ['mean', 'std', 'min']
}).reset_index()

# Display summary statistics
summary_stats.head()

# Set the style and context for the plots
sns.set(style="whitegrid")
plt.figure(figsize=(16, 12))

# Plotting AUROC
plt.subplot(3, 1, 1)
sns.barplot(x='model', y='auroc', hue='dataset', data=df)
plt.title('AUROC by Model and Dataset')
plt.ylabel('AUROC')
plt.xlabel('Model')

# Plotting AUPRC
plt.subplot(3, 1, 2)
sns.barplot(x='model', y='auprc', hue='dataset', data=df)
plt.title('AUPRC by Model and Dataset')
plt.ylabel('AUPRC')
plt.xlabel('Model')

# Plotting FPR@TPR95
plt.subplot(3, 1, 3)
sns.barplot(x='model', y='fpr@tpr95', hue='dataset', data=df)
plt.title('FPR@TPR95 by Model and Dataset')
plt.ylabel('FPR@TPR95')
plt.xlabel('Model')

plt.tight_layout()
plt.show()

# Creating box plots for the metrics
plt.figure(figsize=(16, 12))

# Box Plot for AUROC
plt.subplot(3, 1, 1)
sns.boxplot(x='model', y='auroc', data=df)
plt.title('AUROC Distribution by Model')
plt.ylabel('AUROC')
plt.xlabel('Model')

# Box Plot for AUPRC
plt.subplot(3, 1, 2)
sns.boxplot(x='model', y='auprc', data=df)
plt.title('AUPRC Distribution by Model')
plt.ylabel('AUPRC')
plt.xlabel('Model')

# Box Plot for FPR@TPR95
plt.subplot(3, 1, 3)
sns.boxplot(x='model', y='fpr@tpr95', data=df)
plt.title('FPR@TPR95 Distribution by Model')
plt.ylabel('FPR@TPR95')
plt.xlabel('Model')

plt.tight_layout()
plt.show()

# Pivot the dataframe for heatmap visualization
auroc_pivot = df.pivot(index="dataset", columns="model", values="auroc")
auprc_pivot = df.pivot(index="dataset", columns="model", values="auprc")
fpr_pivot = df.pivot(index="dataset", columns="model", values="fpr@tpr95")

# Creating heatmaps
plt.figure(figsize=(18, 18))

# Heatmap for AUROC
plt.subplot(3, 1, 1)
sns.heatmap(auroc_pivot, annot=True, fmt=".2f", cmap="YlGnBu", cbar_kws={'label': 'AUROC'})
plt.title('AUROC Heatmap')
plt.xlabel('Model')
plt.ylabel('Dataset')

# Heatmap for AUPRC
plt.subplot(3, 1, 2)
sns.heatmap(auprc_pivot, annot=True, fmt=".2f", cmap="YlGnBu", cbar_kws={'label': 'AUPRC'})
plt.title('AUPRC Heatmap')
plt.xlabel('Model')
plt.ylabel('Dataset')

# Heatmap for FPR@TPR95
plt.subplot(3, 1, 3)
sns.heatmap(fpr_pivot, annot=True, fmt=".2f", cmap="YlGnBu", cbar_kws={'label': 'FPR@TPR95'})
plt.title('FPR@TPR95 Heatmap')
plt.xlabel('Model')
plt.ylabel('Dataset')

plt.tight_layout()
plt.show()

# Identify the best performing models for each metric within each dataset type

best_performances_per_dataset = df.groupby('dataset').apply(lambda x: pd.Series({
    'Best_AUROC_Model': x.loc[x['auroc'].idxmax()]['model'],
    'Best_AUROC': x['auroc'].max(),
    'Best_AUPRC_Model': x.loc[x['auprc'].idxmax()]['model'],
    'Best_AUPRC': x['auprc'].max(),
    'Best_FPR@TPR95_Model': x.loc[x['fpr@tpr95'].idxmin()]['model'],
    'Best_FPR@TPR95': x['fpr@tpr95'].min()
})).reset_index()

# Display the best performing models for each dataset type
best_performances_per_dataset

# Calculate the average results for AUROC, AUPRC, and FPR@TPR95 across the five datasets
average_performances = best_performances_per_dataset[['Best_AUROC', 'Best_AUPRC', 'Best_FPR@TPR95']].mean().reset_index()
average_performances.columns = ['Metric', 'Average_Value']

# Display the average performances
average_performances

# Identify the best models based on these averages
best_models = {
    'Best_AUROC_Model': best_performances_per_dataset.loc[best_performances_per_dataset['Best_AUROC'] == best_performances_per_dataset['Best_AUROC'].max(), 'Best_AUROC_Model'].values[0],
    'Best_AUPRC_Model': best_performances_per_dataset.loc[best_performances_per_dataset['Best_AUPRC'] == best_performances_per_dataset['Best_AUPRC'].max(), 'Best_AUPRC_Model'].values[0],
    'Best_FPR@TPR95_Model': best_performances_per_dataset.loc[best_performances_per_dataset['Best_FPR@TPR95'] == best_performances_per_dataset['Best_FPR@TPR95'].min(), 'Best_FPR@TPR95_Model'].values[0]
}

best_models

"""## OOD results"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the CSV file
file_path = '/content/results_train_ood.csv'
df = pd.read_csv(file_path)

# Display the first few rows of the dataframe
df.head()

# Data Cleaning and Preparation
# Remove '%' and convert to float
df['auroc'] = df['auroc'].str.rstrip('%').astype(float)
df['auprc'] = df['auprc'].str.rstrip('%').astype(float)
df['fpr@tpr95'] = df['fpr@tpr95'].str.rstrip('%').astype(float)
df['time execution'] = df['time execution'].astype(float)

# Summary Statistics
summary_stats = df.groupby('model').agg({
    'auroc': ['mean', 'std', 'max'],
    'auprc': ['mean', 'std', 'max'],
    'fpr@tpr95': ['mean', 'std', 'min'],
    'time execution': ['mean', 'std', 'min']
}).reset_index()

# Display summary statistics
summary_stats.head()

# Set the style and context for the plots
sns.set(style="whitegrid")
plt.figure(figsize=(16, 12))

# Plotting AUROC
plt.subplot(3, 1, 1)
sns.barplot(x='model', y='auroc', hue='dataset', data=df)
plt.title('AUROC by Model and Dataset')
plt.ylabel('AUROC')
plt.xlabel('Model')

# Plotting AUPRC
plt.subplot(3, 1, 2)
sns.barplot(x='model', y='auprc', hue='dataset', data=df)
plt.title('AUPRC by Model and Dataset')
plt.ylabel('AUPRC')
plt.xlabel('Model')

# Plotting FPR@TPR95
plt.subplot(3, 1, 3)
sns.barplot(x='model', y='fpr@tpr95', hue='dataset', data=df)
plt.title('FPR@TPR95 by Model and Dataset')
plt.ylabel('FPR@TPR95')
plt.xlabel('Model')

plt.tight_layout()
plt.savefig('/content/results.png')
plt.show()

# Creating box plots for the metrics
plt.figure(figsize=(16, 12))

# Box Plot for AUROC
plt.subplot(3, 1, 1)
sns.boxplot(x='model', y='auroc', data=df)
plt.title('AUROC Distribution by Model')
plt.ylabel('AUROC')
plt.xlabel('Model')

# Box Plot for AUPRC
plt.subplot(3, 1, 2)
sns.boxplot(x='model', y='auprc', data=df)
plt.title('AUPRC Distribution by Model')
plt.ylabel('AUPRC')
plt.xlabel('Model')

# Box Plot for FPR@TPR95
plt.subplot(3, 1, 3)
sns.boxplot(x='model', y='fpr@tpr95', data=df)
plt.title('FPR@TPR95 Distribution by Model')
plt.ylabel('FPR@TPR95')
plt.xlabel('Model')

plt.tight_layout()
plt.savefig('/content/results2.png')
plt.show()

# Pivot the dataframe for heatmap visualization
auroc_pivot = df.pivot(index="dataset", columns="model", values="auroc")
auprc_pivot = df.pivot(index="dataset", columns="model", values="auprc")
fpr_pivot = df.pivot(index="dataset", columns="model", values="fpr@tpr95")

# Creating heatmaps
plt.figure(figsize=(18, 18))

# Heatmap for AUROC
plt.subplot(3, 1, 1)
sns.heatmap(auroc_pivot, annot=True, fmt=".2f", cmap="YlGnBu", cbar_kws={'label': 'AUROC'})
plt.title('AUROC Heatmap')
plt.xlabel('Model')
plt.ylabel('Dataset')

# Heatmap for AUPRC
plt.subplot(3, 1, 2)
sns.heatmap(auprc_pivot, annot=True, fmt=".2f", cmap="YlGnBu", cbar_kws={'label': 'AUPRC'})
plt.title('AUPRC Heatmap')
plt.xlabel('Model')
plt.ylabel('Dataset')

# Heatmap for FPR@TPR95
plt.subplot(3, 1, 3)
sns.heatmap(fpr_pivot, annot=True, fmt=".2f", cmap="YlGnBu", cbar_kws={'label': 'FPR@TPR95'})
plt.title('FPR@TPR95 Heatmap')
plt.xlabel('Model')
plt.ylabel('Dataset')

plt.tight_layout()
plt.savefig('/content/results3.png')
plt.show()

# Identify the best performing models for each metric within each dataset type

best_performances_per_dataset = df.groupby('dataset').apply(lambda x: pd.Series({
    'Best_AUROC_Model': x.loc[x['auroc'].idxmax()]['model'],
    'Best_AUROC': x['auroc'].max(),
    'Best_AUPRC_Model': x.loc[x['auprc'].idxmax()]['model'],
    'Best_AUPRC': x['auprc'].max(),
    'Best_FPR@TPR95_Model': x.loc[x['fpr@tpr95'].idxmin()]['model'],
    'Best_FPR@TPR95': x['fpr@tpr95'].min()
})).reset_index()

# Display the best performing models for each dataset type
best_performances_per_dataset

# Calculate the average results for AUROC, AUPRC, and FPR@TPR95 across the five datasets
average_performances = best_performances_per_dataset[['Best_AUROC', 'Best_AUPRC', 'Best_FPR@TPR95']].mean().reset_index()
average_performances.columns = ['Metric', 'Average_Value']

# Display the average performances
average_performances

# Identify the best models based on these averages
best_models = {
    'Best_AUROC_Model': best_performances_per_dataset.loc[best_performances_per_dataset['Best_AUROC'] == best_performances_per_dataset['Best_AUROC'].max(), 'Best_AUROC_Model'].values[0],
    'Best_AUPRC_Model': best_performances_per_dataset.loc[best_performances_per_dataset['Best_AUPRC'] == best_performances_per_dataset['Best_AUPRC'].max(), 'Best_AUPRC_Model'].values[0],
    'Best_FPR@TPR95_Model': best_performances_per_dataset.loc[best_performances_per_dataset['Best_FPR@TPR95'] == best_performances_per_dataset['Best_FPR@TPR95'].min(), 'Best_FPR@TPR95_Model'].values[0]
}

best_models